\section{Measurements}\label{sec:measurements}
This section describes possible measurements on the execution of GRATiS and comparisons between IOSTSs and IOGGs. This is done to compare the effectiveness of both formalisms in MBT.The comparisons between the models are set out in the next sections, which are:
\begin{enumerate}
\item Simulation and redundancy
\item Model complexity
\item Extendability
\end{enumerate}
The measurements on the performance of GRATiS follow.

\subsection{Simulation and redundancy}
The generated IOSTS and the modelled IOSTS can be compared. It can be observed whether the generated IOSTS simulates the modelled IOSTS and vice versa. When either is not the case, the models show a different possible behavior for the SUT.

Simulation between two STSs can be done by creating the LTSs from the STSs first. LTSMin~\footnote{http://fmt.cs.utwente.nl/tools/ltsmin/} is a tool which can check the (bi)simulation on LTSs. However, creating the LTSs from STSs becomes difficult on large models. Therefore, another solution is chosen.

ATM can be used to find diffrences between two IOSTSs, by using one as the model and the other as the SUT. The SUT tries to copy the stimuli done by the model and the model tries to copy responses done by the SUT. ATM can then find differences in behavior between both IOSTSs. This technique is used to find non-conformance between the generated and modelled IOSTSs. This is done by letting the test run reach 100\% switch relation coverage on both models. For purposes of the next measurement, we assume then that a bisimulation exists between both models.

\begin{definition}\label{def:redundancy} Model redundancy\\
It is possible that a generated IOSTS $s$ is larger than a modelled IOSTS $t$, even if both simulate each other. If $t$ simulates $s$, it is measured whether the set of switch relations or location variables is strictly smaller in $t$ than in $s$, while the other set is at least as small in $t$ as in $s$. Formally:
\vspace{5px} \\
$\mathit{traces}(s) \subseteq \mathit{traces}(t) \land ((|\Switches_t| < |\Switches_s| \land |\LocationVariables_t| \leq |\LocationVariables_s|) \lor (|\Switches_t| \leq |\Switches_s| \land |\LocationVariables_t| < |\LocationVariables_s|)$
\vspace{5px} \\
This indicates the the IOSTS $s$ has redundancy.
\end{definition}

\subsection{Model complexity}\label{sec:complexity_measurement}
A good way of testing the complexity of the IOSTS and the IOGG is to hold an extensive social experiment, where groups create and maintain models in either formalism. However, this is out of the scope for this report. More is written about this social experiment in the Future Work section~\ref{sec:future-work}.

Instead of a social experiment, we investigated software complexity measurements in the literature and tested their applicability for IOGGs and IOSTSs. The investigated complexity measurements are:
\begin{enumerate}
\item Halstead's software science
\item Cyclomatic complexity
\item System complexity
\end{enumerate}

\paragraph*{Halstead's software science} The complexity of the generated IOSTS and the IOGG can be measured using Halstead's software science~\cite{Halstead:software-science}. This method is used in measuring software complexity and the prediction of faults. However, it can also be used in analyzing model complexity. In Halstead's software science, the operators and operands in the program code are counted. The operators are the function symbols, the operands are the identifiers. However, in order to apply these concepts to our setting, we have to identify what we consider to be operators and operands.

IOSTSs and IOGGs both have identifiers and function symbols. However, they also have nodes and edges. In an IOSTS, the locations are counted as nodes, the switch relations as edges. Nodes and edges are considered to be operands. In GROOVE, colors indicate a restriction or node/edge removal/creation. The node and edge colors are therefore considered as operators.

The distinct number of operators ($n_1$) and operands ($n_2$) are counted as well as the total number of operator occurrences ($N_1$) and operand occurrences ($N_2$). These metrics combined lead to the \textit{Volume} (V) of the models.
\vspace{10px}\begin{definition} Halstead's Volume (V) function \\
$(N_1+N_2)*\mathit{log}_2(n_1+n_2)$
\end{definition}\vspace{10px}
In Halstead's software science, the volume of a program and a constant for the number of faults per volume unit are combined to give the expected faults in a program. Therefore, comparing the volumes of the IOSTS and IOGG gives an indication of the relative model complexity.

\paragraph*{Cyclomatic Complexity} COMMENT Ik heb intensief emails gewisseld met Lodewijk Bergmans over de toepassing van cyclomatic complexity, maar dit lijkt niet geschikt hier. Ik zal het wel behandelen $/$COMMENT
% vanwege het nodig hebben van begin en eind punten in een transitiesysteem. Voor STS is dat al lastig vanwege loops, maar in GG vrijwel onmogelijk omdat de interacties tussen 

\paragraph*{System Complexity} COMMENT mooie, simpele metric voor OO. Niet toepasbaar hier, want onmogelijk om modules te definieren $/$COMMENT
% modules -> fan-in, fan-out, nodig voor Structural Complexity & Data Complexity

\subsection{Extendability}
The models can be extended to include more functionality. In this measurement, a realistic scenario is introduced where additional functionality is required. It is then measured how much the complexity increases, using the measurment in section~\ref{sec:complexity_measurement}.

\subsection{Performance}
The performance on runtime and heap-size on the IOSTS generated by GRATiS is measured. After the IOSTS is generated we assume the run-time and heap-size for the testing part are the same for both the generated IOSTS and the modelled IOSTS. Therefore, only the runtime and heap size of the IOSTS generation are measured. When dividing the results for each model by the corresponding volume of the model, a relative measurement is obtained which can be compared, to see how the algorithm scales.
