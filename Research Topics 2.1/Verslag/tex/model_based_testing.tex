\section{Model-based Testing}\label{sec:model_based_testing}
Formal testing theory was introduced by De Nicola et al.~\cite{denicola:testing}. This testing theory was first used in algorithms for automatic test generation by Brinksma~\cite{brinksma:testing}. Tretmans gives a formal approach to protocol conformance testing (whether a protocol conforms to its specifications) in~\cite{Tretmans:conformancetesting}. Model-based testing is the process of automatically generating test-cases based on a specification. A good overview of model-based testing theory and past research is given in "Model-Based Testing of Reactive Systems"~\cite{Broy:ModelBasedTesting}. %A tool for the automatic synthesis of test cases for nondeterministic systems is TGV~\cite{Jard:TGV}. 

Model-based testing is a testing technique where a System Under Test (SUT) is tested for conformance to a model description of the system. The general setup for this process is depicted in Figure~\ref{fig:model_based_testing}. The specification, given as a model, of a system is given to a test derivation component which generates test cases. These test cases are passed to a component that executes the test cases on the SUT. Tests are executed by providing input/stimuli to the SUT and monitoring the output/response. The test execution component evaluates the test cases, the stimuli and the responses. It gives a 'pass' or 'fail' verdict whether the SUT conforms to the specification or not respectively.

\begin{figure}[h]
  \begin{center}
    \includegraphics[width=0.75\textwidth]{model-based-testing.eps}
  \end{center}
  \caption{A general model-based testing setup}
  \label{fig:model_based_testing}
\end{figure}

This type of model-based testing is called \textit{batch testing} or \textit{offline testing}. Another type of model-based testing is \textit{on the fly} testing. The main difference is that no test cases are derived, instead a transition in the model is chosen and tested on the system directly. The general architecture for this process is shown in Figure~\ref{fig:model_based_testing_on_the_fly}. A tool for on-the-fly testing is TorX~\cite{Tretmans:TorX}, which integrates automatic test generation, test execution, and test analysis. A version of this tool written in Java under continuous development is JTorX~\cite{Belinfante:JTorX}.

\begin{figure}[h]
  \begin{center}
    \includegraphics[width=0.75\textwidth]{mbt-on-the-fly.eps}
  \end{center}
  \caption{A general 'on-the-fly' model-based testing setup}
  \label{fig:model_based_testing_on_the_fly}
\end{figure}

Variations of state machines and transition systems have been widely used as the underlying model for test generation. Other tools use the structure of data types to generate test data. First, two types of models are introduced. These are basic formalisms useful to understand the models in the rest of the paper. Then, the notion of \textit{coverage} is explained.

\subsection{Labelled Transition Systems}
A labelled transition system is a structure consisting of states with labelled transitions between them.

\subsubsection{Definition}
A labelled transition system is a 4-tuple	$\langle Q, L, T, q0\rangle$, where:
\begin{itemize}
\item $Q$ is a finite, non-empty set of states
\item $L$ is a finite set of labels
\item $T \in Q \times (L \cup \{\tau\}) \times Q$, with $\tau \notin L$, is the transition relation
\item $q0 \in Q$ is the initial state.
\end{itemize}
We write $q \xrightarrow{\mu}q'$ if there is a transition labelled $\mu$ from state q to state q', i.e., $(q, μ, q') \in T$. The informal idea of such a transition is that when the system is in state $q$ it may perform action $\mu$, and go to state $q'$. 

%Suppose that in state $q'$ the system can perform action $μ'$, i.e., $q'\xrightarrow{$\mu'$}q''$, then these transitions can be composed: q μ −q μ −−→q, which is written as q μ·μ −−−→q. In general, the
%composition of transitions q1
%μ1·μ2·...·μn −−−−−−−−→q2 expresses that the system, when in
%state q1, can perform the sequence of actions μ1·μ2· . . . ·μn, and may end in state
%q2. The use of may is important here: because of non-determinism, it may be
%the case that the system can also perform the same sequence of actions, but end
%in another state: q1
%μ1·μ2·...·μn −−−−−−−−→q3 with q2 = q3.

\subsection{Input-Output Transition Systems}
A useful transition system for model-based testing is the Input-Output Transition System (IOTS) by Tretmans\cite{Tretmans:testgeneration}. Assuming that implementations communicate with their environment via inputs and outputs, this formalism is useful for describing system behavior. These are similar to LTSs with the exception that labels have a type. This type can be 'input' or 'output'. 

An example of such an IOTS is shown in Figure~\ref{fig:iots_example}. This system allows an input of 20 or 50 cents and then outputs tea or coffee accordingly. The inputs are preceded by a question mark, the outputs are preceded by an exclamation mark. This system is a specification of a coffee machine. A test case can also be described by an IOTS. A test case for the coffee machine is given in Figure~\ref{fig:iots_test}. The test case is derived from the coffee machine IOTS in the Test Derivation component. The Test Execution component applies the stimulus '50c' to the SUT. When the SUT responds with 'tea', the test case results in a fail verdict and when the SUT responds with 'coffee', the test case results in a pass verdict. The pass and fail verdicts are two special states in the test case, which are sink states, i.e., once in either of those the test case cannot leave that state. 

Test cases should always reach a pass or fail state within finite time. This requirement ensures that the testing process halts.
\begin{figure}[h]
  \begin{center}
    \subfloat[An IOTS]{\label{fig:iots_example}\input{./img/iots-example.tex}}
    \subfloat[An IOTS test case]{\label{fig:iots_test}\input{./img/iots-test.tex}}
  \end{center}
  \caption{The specification of a coffee machine and a test case as an IOTS}
\end{figure}

%Unnecessary nondeterminism should be avoided in test cases \cite{Tretmans:ModelBasedTesting}: "In the first place, this implies that the test case itself is deterministic. In the second place, this means that a tester should never offer more than one input action (from the perspective of the implementation) at a time. Since the implementation is able to accept any input action, offering more inputs would always lead to an unnecessarily non-deterministic continuation of the test run. Having a deterministic test case does not imply that a test run has a unique result: due to non-determinism in the implementation under test, and due to non-determinism in the test run itself, the repetition of a test run may lead to a different result".

\subsection{Coverage}\label{sec:coverage}
The amount of tests that can be generated from a model is potentially infinite. Therefore, there must be a test selection strategy to maximize the quality of the tests while minimizing the time spent testing. Coverage statistics help with test selection. This statistic indicates how much of the SUT is tested. When the SUT is a black-box, typical coverage metrics are state and transition coverage of the model~\cite{Lee:testing, Nachmanson:testing, Hasan:testing}.

As an example, the coverage metrics of the IOTS test case example in~\ref{fig:iots_test} are calculated. The test case tests one path through the specification and passes through 3 out of 4 states and 2 out of 4 transitions. The state coverage is therefore 75\% and the transition coverage is 50\%.

